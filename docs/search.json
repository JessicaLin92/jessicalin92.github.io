[
  {
    "objectID": "Data Viz.html",
    "href": "Data Viz.html",
    "title": "Project 1: Data Visualization",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n#Data Visualization on mammals’ body weight and their time spent awake\n\nnewdata&lt;- msleep %&gt;% filter(!is.na(vore)) |&gt;\n  filter(bodywt&lt; 300)\n\nggplot(newdata, aes(x= bodywt, y=awake, color= vore))+\n  geom_point(na.rm = TRUE)+\n  labs (\n    x = \"The body weight in kg\",\n    y = \"The amount of time spent awake\",\n    title = \"Mammals' body weight and their time spent awake\", \n    subtitle = \"Excluding mammals that is hearvier than 300 kg/ outliners\"\n  )\n\n\n\n\n\n\n\n\n(Source from TidyTuesday; from V. M. Savage and G. B. West.)\n#Data Visualization on the age of orange tree and their trunk circumferences\n\nggplot(Orange, aes(x=age, y=circumference, color=Tree))+\n  geom_point()+\n  labs(\n    x= \"The age of the tree\", \n    y=\"A numeric vector of trunk circumferences (mm)\", \n    title= \"The age of orange tree and their trunk circumferences\"\n  )\n\n\n\n\n\n\n\n\n(Source from Tidytuesday; Draper, N. R. and Smith, H. (1998), Applied Regression Analysis (3rd ed), Wiley (exercise 24.N).and Pinheiro, J. C. and Bates, D. M. (2000) Mixed-effects Models in S and S-PLUS, Springer.)"
  },
  {
    "objectID": "Text-Analysis.html",
    "href": "Text-Analysis.html",
    "title": "Project 2: Text Analysis",
    "section": "",
    "text": "library(\"tidytuesdayR\")\nlibrary(\"tidyverse\")\n\nnetflix_titles &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv')\n\nshow_col_types = FALSE\n\nSo for this project, we will be looking at the Netflix products that are filmed in United states only.\n\nlibrary(dplyr)\nlibrary(stringr)\n\nUSfilms &lt;- netflix_titles |&gt;\n    filter(str_detect(country, \"United States\")) |&gt;\n  select(title, country, type) |&gt; \n  filter(!is.na(everything))\n\nNext, we will find out the first letter of the Netflix productions, and calculate the occurrences of each letter in the Netflix productions\n\nN_firstword &lt;- USfilms |&gt;\nfilter(str_detect(title, \"^[A-Z]\")) |&gt;\n  mutate(first_word = str_extract(title, \"^\\\\w\")) |&gt;\n  group_by(first_word) |&gt;\n  mutate(count = n())\n\nprint(N_firstword)\n\n# A tibble: 3,241 × 5\n# Groups:   first_word [26]\n   title                                   country        type  first_word count\n   &lt;chr&gt;                                   &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt;      &lt;int&gt;\n 1 A 3 Minute Hug                          Mexico, Unite… Movie A            223\n 2 A Babysitter's Guide to Monster Hunting United States  Movie A            223\n 3 A Bad Moms Christmas                    United States… Movie A            223\n 4 A Boy Called Po                         United States  Movie A            223\n 5 A Bridge Too Far                        United States… Movie A            223\n 6 A California Christmas                  United States  Movie A            223\n 7 A Champion Heart                        United States  Movie A            223\n 8 A Christmas Prince                      United States  Movie A            223\n 9 A Christmas Prince: The Royal Baby      United States  Movie A            223\n10 A Christmas Prince: The Royal Wedding   United States  Movie A            223\n# ℹ 3,231 more rows\n\n\nNow we can visualize it!\n\nlibrary(ggplot2)\n\nggplot(N_firstword, aes(x= first_word, fill=type)) +\n   geom_bar() +\n  labs(title = \"Occurrences of different first letter in US Netflix Productions\",\n       x = \"First Letter (A ~Z)\",\n       y = \"Number of Occurrences\") \n\n\n\n\n\n\n\n\nSo according to the list, the most first letter in the US Netflix production is “T” which is pretty easy to understand since most of the movie may start with the word ‘The’.\nNow I am wondering about how much US netflix production are starting in numbers and their occurrences.\n\nN_firstdigit &lt;- USfilms |&gt;\n  filter(str_detect(title, \"^\\\\d+\")) |&gt;\n  mutate(first_digit = str_extract(title, \"^\\\\d\")) |&gt;\n  group_by(first_digit) |&gt;\n  mutate(count = n())\n\nprint(N_firstdigit)\n\n# A tibble: 49 × 5\n# Groups:   first_digit [8]\n   title            country                        type    first_digit count\n   &lt;chr&gt;            &lt;chr&gt;                          &lt;chr&gt;   &lt;chr&gt;       &lt;int&gt;\n 1 9                United States                  Movie   9               2\n 2 21               United States                  Movie   2               8\n 3 187              United States                  Movie   1              21\n 4 1922             United States                  Movie   1              21\n 5 1983             Poland, United States          TV Show 1              21\n 6 3022             United States                  Movie   3               5\n 7 22-Jul           Norway, Iceland, United States Movie   2               8\n 8 1 Chance 2 Dance United States                  Movie   1              21\n 9 1 Mile to You    United States                  Movie   1              21\n10 10,000 B.C.      United States, South Africa    Movie   1              21\n# ℹ 39 more rows\n\n\nAnd now we visualize it!\n\n ggplot(N_firstdigit, aes(x= first_digit, fill=type)) +\n   geom_bar() +\n  labs(title = \"Occurrences of different first digit in US Netflix Productions\",\n       x = \"First Digit (0~9)\",\n       y = \"Number of Occurrences\") \n\n\n\n\n\n\n\n\nSo the graph displays a pretty interesting fact, which is that the digit “1” appear the most in both movies and TV shows in US Netflix production. I suspect that the reason may be because Many documentary titles or reality shows often include a numeric element, such as rankings or competitions, and those often start with number ‘1’.\nSome other interesting fact is that there is no TV shows title that starts with the digit ‘4’ and there is no Movies title that starts with the digit ‘7’ in the US Netflix production.\n\nInsight\nThe analysis of first letters in US Netflix productions reveals some intriguing patterns:\n\nDominance of “T”: The letter “T” is the most common starting letter for titles. This is likely due to the prevalence of titles that begin with “The,” a common article in English.\nPrevalence of the Digit “1”: The digit “1” appears most frequently as the starting digit in both movies and TV shows.\nAbsence of Titles Starting with Certain Digits: There are no TV shows starting with the digit “4,” possibly indicating a lack of popular content or marketing focus. Similarly, no movies begin with “7,” which may reflect industry naming trends or a scarcity of suitable productions.\n\n\n\nReference\nThe data set Netflix_Titles comes from Kaggle w/ credit to Shivam Bansal."
  },
  {
    "objectID": "Simulation.html",
    "href": "Simulation.html",
    "title": "Project 3: Simulation",
    "section": "",
    "text": "For this project, we aimed to construct a simulation of students doing course registration at the Claremont Colleges. In order to create this simulation, We first defined a function that simulate the regiration action, next we assign students into a list that represent the order of course registration time. Last, we define the result for whether one particular student can get into the class such as 1 being True: the student can get into the class, or 0 being False: the student would not get into the class.\n\nsimulate_registration &lt;- function(class_size, num_students, priority_weight = NULL) {\n  if (!is.null(priority_weight)) {\n    priority &lt;- sample(1:num_students, num_students, replace = TRUE, prob = priority_weight)\n    priority_order &lt;- order(priority)\n  } else {\n    priority_order &lt;- sample(1:num_students)\n  }\n\nregistered_students &lt;- priority_order[1:class_size]\nreturn(ifelse(1 %in% registered_students, TRUE, FALSE))\n}\n\nAfter we finish setting up and defining the function, now we run it with map to rerun and simulate the event.For our simulation, because of how small the class at the Claremont colleges normally are, let’s put 20 as the class_size for this imaginary class. For the students number, although the total students number may be high, however, we should only consider the numnber of students that may be interested into taking this imaginary class, thus let’s assume there are 50 students wanting to get into this class. In turns of priorit weight, since all claremont colleges students register at the same time, the only difference is the grade year, therefore I am setting the order as seniors goes first, and then junior, then sophomore, and last will be freshman. For this 10 will be seniors, 10 will be juniors, and 10 will be sophomores, and the rest of the 20 students will be freshman.\nFor number of simulations, I choose to run 1000 times because in probability simulations, running multiple trials reduces random variability and gives a more stable estimate of the true probability.\n\nlibrary(purrr)\n\nclass_size &lt;- 20\nnum_students &lt;- 50\nnum_simulations &lt;- 1000\npriority_weight &lt;- c(rep(0.4, 10), rep(0.3, 10), rep(0.2, 10), rep(0.1, 20))\n\nresults &lt;- map_int(1:num_simulations, ~ simulate_registration(class_size = class_size, num_students = num_students, priority_weight = priority_weight))\n\nnum_true &lt;- sum(results == 1)\nprobability &lt;- num_true / num_simulations\n\nprint(paste(\"Probability that student #1 gets a spot:\", probability))\n\n[1] \"Probability that student #1 gets a spot: 0.395\"\n\n\nAfter a few trials of 1000 times simulations, the general probability value we are getting are between 0.38 ~ 0.42, which basically concluded that for this course registration simulation with 50 students trying to get in a 20 spot class, the probability of getting in is around 0.4.\n\nlibrary(ggplot2)\n\ndata &lt;- data.frame(\n  Trial = 1:num_simulations,\n  Outcome = as.factor(results)\n)\n\nggplot(data, aes(x = Outcome)) +\n  geom_bar() +\n  labs(title = \"Simulation of Course Registration\",\n       x = \"Outcome (1 = Got in, 0 = Did not get in)\",\n       y = \"Frequency\") \n\n\n\n\n\n\n\n\nThis plot display the results of the 1000 trials that we run, and within these 1000 times, whether the student gets into the class. 1 being they did manager to get into the class, and 0 being they didn’t.\n#Conclusion\nFor this project, we use R to simulate the course registration event here at 5C colleges, although the numbers we input are very much based on assumptions, we do successfully use R to simulate and get a sense of the probabilities of 1 student getting into the class that 50 students are interested in.\nSome possible limitation or improvement for future simulation:\n\nCould potentially take the concept of ‘majors’ into consideration as they tends to have a prioritizes when registering for their major classes.\nIn the similar manner, we can also take into consideration of ‘perms’ since this is the way professor approve or disapprove students’ ability to register the class."
  },
  {
    "objectID": "SQL.html",
    "href": "SQL.html",
    "title": "Project 4: SQL",
    "section": "",
    "text": "library(dbplyr)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:dbplyr':\n\n    ident, sql\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\n\n\nlibrary(RMariaDB)\ncon_wai &lt;- dbConnect(\n  MariaDB(), host = \"scidb.smith.edu\",\n  user = \"waiuser\", password = \"smith_waiDB\", \n  dbname = \"wai\"\n)\nMeasurements &lt;- tbl(con_wai, \"Measurements\")\nPI_Info &lt;- tbl(con_wai, \"PI_Info\")\nSubjects &lt;- tbl(con_wai, \"Subjects\")\n\n\nSHOW TABLES;\n\n\n7 records\n\n\nTables_in_wai\n\n\n\n\nCodebook\n\n\nMeasurements\n\n\nMeasurements_pre2020\n\n\nPI_Info\n\n\nPI_Info_OLD\n\n\nSubjects\n\n\nSubjects_pre2020\n\n\n\n\n\nFor this project, we are duplicate the Figure 1 from Voss (2020). We will query the WAI Database and build a data set in order to graph using ggplot.\n\nSELECT \n    Identifier, Instrument, \n    COUNT(DISTINCT CONCAT(SubjectNumber, Ear)) AS Unique_Ears,\n    Frequency,\n    AVG(Absorbance) AS MeanAbsorbance\nFROM Measurements\nWHERE Identifier IN ('Abur_2014', 'Feeney_2017', 'Groon_2015', \n                     'Lewis_2015', 'Liu_2008', 'Rosowski_2012', \n                     'Shahnaz_2006', 'Shaver_2013', 'Sun_2016', \n                     'Voss_1994', 'Voss_2010', 'Werner_2010')\nGROUP BY Identifier, Instrument, Frequency\nORDER BY Frequency;\n\n\nDisplaying records 1 - 10\n\n\nIdentifier\nInstrument\nUnique_Ears\nFrequency\nMeanAbsorbance\n\n\n\n\nLewis_2015\nOther\n14\n0.00000\n0.9999481\n\n\nLewis_2015\nOther\n14\n5.85938\n0.9999481\n\n\nLewis_2015\nOther\n14\n11.71880\n0.9999481\n\n\nLewis_2015\nOther\n14\n17.57810\n0.0942423\n\n\nLewis_2015\nOther\n14\n23.43750\n0.0955518\n\n\nLewis_2015\nOther\n14\n29.29690\n0.0972262\n\n\nLewis_2015\nOther\n14\n35.15620\n0.0992588\n\n\nVoss_1994\npreHearID\n10\n39.06250\n-0.0280960\n\n\nLewis_2015\nOther\n14\n41.01560\n0.1016413\n\n\nLewis_2015\nOther\n14\n46.87500\n0.1043644\n\n\n\n\n\n\ngraph_data &lt;- \"\nSELECT \n    m.Identifier,\n    m.Instrument,\n    COUNT(DISTINCT CONCAT(m.SubjectNumber, m.Ear)) AS Unique_Ears, -- Count unique ears\n    m.Frequency,\n    AVG(m.Absorbance) AS MeanAbsorbance\nFROM Measurements m\nWHERE m.Identifier IN ('Abur_2014', 'Feeney_2017', 'Groon_2015', \n                        'Lewis_2015', 'Liu_2008', 'Rosowski_2012', \n                        'Shahnaz_2006', 'Shaver_2013', 'Sun_2016', \n                        'Voss_1994', 'Voss_2010', 'Werner_2010')\n  AND m.Frequency &gt; 200 -- Filter relevant frequencies\n  AND m.Frequency &lt; 8000 -- Align with the x-axis scale\nGROUP BY m.Identifier, m.Instrument, m.Frequency\nORDER BY m.Identifier, m.Frequency;\n\"\n\n\ngraph_plot &lt;- dbGetQuery(con_wai, graph_data)\n\nlibrary(ggplot2)\n\nggplot(graph_plot, aes(x = Frequency, y = MeanAbsorbance, color = Identifier)) +\n  geom_line() +\n  scale_x_log10() + \n  labs(\n    title = \"Mean Absorbance from Each Publication in WAI Database\",\n    x = \"Frequency (Hz)\",\n    y = \"Mean Absorbance\") +\n    theme_minimal() \n\n\n\n\n\n\n\n\nThe graph displays the mean absorbance (on y-axis) across different frequencies (Hz) (on x-axis) for multiple studies, each represented by a distinct line. The graph compares how absorbance patterns vary by frequency among studies using different systems.\n\nPart 2 - Specific Group of interest\nFor part 2, we are examining subjects with different race, especially Black and Caucasian.\n\nSELECT \n    Identifier,\n    COUNT(*) AS Total_Subjects,\n    COUNT(DISTINCT Race) AS Race_Groups,\n    SUM(CASE WHEN Race = 'Unknown' THEN 1 ELSE 0 END) AS Unknown\nFROM Subjects\nGROUP BY Identifier\nHAVING Race_Groups &gt; 1 AND (Total_Subjects - Unknown) &gt; 0; \n\n\nDisplaying records 1 - 10\n\n\nIdentifier\nTotal_Subjects\nRace_Groups\nUnknown\n\n\n\n\nAithal_2014b\n184\n2\n0\n\n\nAithal_2015\n141\n4\n0\n\n\nDowning_2022\n924\n7\n108\n\n\nEllison_2012\n88\n5\n4\n\n\nHunter_2016\n182\n3\n0\n\n\nKeefe_2012\n55\n5\n10\n\n\nLewis_2015\n14\n4\n0\n\n\nMerchant_2015\n32\n3\n4\n\n\nMerchant_2020\n29\n2\n0\n\n\nMerchant_2021\n35\n4\n1\n\n\n\n\n\n\nquery_race &lt;- \"\nSELECT \n    Identifier,\n    COUNT(*) AS Total_Subjects,\n    COUNT(DISTINCT Race) AS Race_Groups,\n    SUM(CASE WHEN Race = 'Unknown' THEN 1 ELSE 0 END) AS Unknown\nFROM Subjects\nGROUP BY Identifier\nHAVING Race_Groups &gt; 1 AND (Total_Subjects - Unknown) &gt; 0;\"\n\ndiverse_studies &lt;- dbGetQuery(con_wai, query_race)\n\nprint(diverse_studies)\n\n      Identifier Total_Subjects Race_Groups Unknown\n1   Aithal_2014b            184           2       0\n2    Aithal_2015            141           4       0\n3   Downing_2022            924           7     108\n4   Ellison_2012             88           5       4\n5    Hunter_2016            182           3       0\n6     Keefe_2012             55           5      10\n7     Lewis_2015             14           4       0\n8  Merchant_2015             32           3       4\n9  Merchant_2020             29           2       0\n10 Merchant_2021             35           4       1\n11    Myers_2018            543           7     151\n12 Nakajima_2012             30           3      17\n13 Rosowski_2012             29           4       0\n14  Shahnaz_2006            126           2       0\n15   Shaver_2013             48           4       1\n16      Sun_2016             84           5       2\n17      Sun_2023           3582           4       0\n\n\n\n\nSELECT \n    m.Identifier,       \n    s.Race AS GroupName,  \n    m.Frequency,         \n    AVG(m.Absorbance) AS MeanAbsorbance \nFROM Measurements m\nJOIN Subjects s \n    ON m.SubjectNumber = s.SubjectNumber\n    AND m.Identifier = s.Identifier\nWHERE m.Identifier IN ('Abur_2014', 'Feeney_2017', 'Groon_2015', \n                        'Lewis_2015', 'Liu_2008', 'Rosowski_2012', \n                        'Shahnaz_2006', 'Shaver_2013', 'Sun_2016', \n                        'Voss_1994', 'Voss_2010', 'Werner_2010') \n  AND m.Frequency &gt; 200            \n  AND m.Frequency &lt; 8000\n  AND m.Absorbance &gt;= 0            \n  AND s.Race IN ( 'Chinese', 'Caucasian')   \nGROUP BY m.Identifier, s.Race, m.Frequency \nORDER BY m.Identifier, s.Race, m.Frequency;\n\n\nDisplaying records 1 - 10\n\n\nIdentifier\nGroupName\nFrequency\nMeanAbsorbance\n\n\n\n\nLewis_2015\nCaucasian\n205.078\n0.2534996\n\n\nLewis_2015\nCaucasian\n210.938\n0.2592639\n\n\nLewis_2015\nCaucasian\n216.797\n0.2649114\n\n\nLewis_2015\nCaucasian\n222.656\n0.2704362\n\n\nLewis_2015\nCaucasian\n228.516\n0.2758337\n\n\nLewis_2015\nCaucasian\n234.375\n0.2811003\n\n\nLewis_2015\nCaucasian\n240.234\n0.2862337\n\n\nLewis_2015\nCaucasian\n246.094\n0.2912328\n\n\nLewis_2015\nCaucasian\n251.953\n0.2960975\n\n\nLewis_2015\nCaucasian\n257.812\n0.3008293\n\n\n\n\n\n\nquery_race &lt;- \"\n\nSELECT \n    m.Identifier,       \n    s.Race AS GroupName,  \n    m.Frequency,         \n    AVG(m.Absorbance) AS MeanAbsorbance \nFROM Measurements m\nJOIN Subjects s \n    ON m.SubjectNumber = s.SubjectNumber\n    AND m.Identifier = s.Identifier\nWHERE m.Identifier IN ('Abur_2014', 'Feeney_2017', 'Groon_2015', \n                        'Lewis_2015', 'Liu_2008', 'Rosowski_2012', \n                        'Shahnaz_2006', 'Shaver_2013', 'Sun_2016', \n                        'Voss_1994', 'Voss_2010', 'Werner_2010') \n  AND m.Frequency &gt; 200            \n  AND m.Frequency &lt; 8000\n  AND m.Absorbance &gt;= 0            \n  AND s.Race IN ( 'Black', 'Caucasian')  \nGROUP BY m.Identifier, s.Race, m.Frequency \nORDER BY m.Identifier, s.Race, m.Frequency;\"\n\n\ndata_absorption &lt;- dbGetQuery(con_wai, query_race)\n\n\nhead(data_absorption)\n\n  Identifier GroupName Frequency MeanAbsorbance\n1 Lewis_2015 Black       205.078      0.2449420\n2 Lewis_2015 Black       210.938      0.2506140\n3 Lewis_2015 Black       216.797      0.2561765\n4 Lewis_2015 Black       222.656      0.2616243\n5 Lewis_2015 Black       228.516      0.2669527\n6 Lewis_2015 Black       234.375      0.2721585\n\n\n\nggplot(data_absorption, aes(x = Frequency, y = MeanAbsorbance, color = GroupName)) +\n  geom_line() +\n  facet_wrap(~ Identifier) +  \n  scale_x_log10() +          \n  labs(\n    title = \"Mean Absorbance by Ethnicity Across Multiple Studies\",\n    x = \"Frequency (Hz)\",\n    y = \"Mean Absorbance\",\n    color = \"Race\"\n  ) +\n  theme_minimal()"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jessica (YongJie) Lin",
    "section": "",
    "text": "This is Jessica’s website.\nWelcome! I am a junior student at Pitzer studying Organizational Studies and Psychology, with a minor in data science.\n\nContact information\nLinkedIn\nGitHub\nEmail: jeslin@students.pitzer.edu"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Education\nBachelor of Arts (B.A.) in Organizational Studies and Psychology; Minor in Data Science.\n\n\nProfessional Experience\nInternational Students Orientation Assistant\nStudent Success Assistant\nAcademic Guide\n\n\nLeaderships\nPitzer International Students Association (PISA)\nThe Pasifika Asian Student Union (PASU)"
  }
]