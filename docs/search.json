[
  {
    "objectID": "Data Viz.html",
    "href": "Data Viz.html",
    "title": "Project 1: Data Visualization",
    "section": "",
    "text": "library(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.4     ✔ readr     2.1.5\n✔ forcats   1.0.0     ✔ stringr   1.5.1\n✔ ggplot2   3.5.1     ✔ tibble    3.2.1\n✔ lubridate 1.9.3     ✔ tidyr     1.3.1\n✔ purrr     1.0.2     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n#Data Visualization on mammals’ body weight and their time spent awake\n\nnewdata&lt;- msleep %&gt;% filter(!is.na(vore)) |&gt;\n  filter(bodywt&lt; 300)\n\nggplot(newdata, aes(x= bodywt, y=awake, color= vore))+\n  geom_point(na.rm = TRUE)+\n  labs (\n    x = \"The body weight in kg\",\n    y = \"The amount of time spent awake\",\n    title = \"Mammals' body weight and their time spent awake\", \n    subtitle = \"Excluding mammals that is hearvier than 300 kg/ outliners\"\n  )\n\n\n\n\n\n\n\n\n(Source from TidyTuesday; from V. M. Savage and G. B. West.)\n#Data Visualization on the age of orange tree and their trunk circumferences\n\nggplot(Orange, aes(x=age, y=circumference, color=Tree))+\n  geom_point()+\n  labs(\n    x= \"The age of the tree\", \n    y=\"A numeric vector of trunk circumferences (mm)\", \n    title= \"The age of orange tree and their trunk circumferences\"\n  )\n\n\n\n\n\n\n\n\n(Source from Tidytuesday; Draper, N. R. and Smith, H. (1998), Applied Regression Analysis (3rd ed), Wiley (exercise 24.N).and Pinheiro, J. C. and Bates, D. M. (2000) Mixed-effects Models in S and S-PLUS, Springer.)"
  },
  {
    "objectID": "Text-Analysis.html",
    "href": "Text-Analysis.html",
    "title": "Project 2: Text Analysis",
    "section": "",
    "text": "library(\"tidytuesdayR\")\nlibrary(\"tidyverse\")\n\nnetflix_titles &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv')\n\nshow_col_types = FALSE"
  },
  {
    "objectID": "Text-Analysis.html#part-one-first-character-of-the-production-title",
    "href": "Text-Analysis.html#part-one-first-character-of-the-production-title",
    "title": "Project 2: Text Analysis",
    "section": "Part One: First Character of the Production Title",
    "text": "Part One: First Character of the Production Title\nFor this project, we will be looking at the Netflix products that are filmed in United states only. In order to accomplish this, we apply a filter in the country column that detect strings “United States”, and remove anything that has n/a by filtering as well. For the purpose of out project, the three main variables we need will be the title, country, and the type of the Netflix product, thus, we use select to select these variables.\n\nlibrary(dplyr)\nlibrary(stringr)\n\nUSfilms &lt;- netflix_titles |&gt;\n    filter(str_detect(country, \"United States\")) |&gt;\n  select(title, country, type) |&gt; \n  filter(!is.na(everything))\n\nNow we have obtain the relevant information, we will find out the first letter of the Netflix productions, and calculate the occurrences of each letter in the Netflix productions.\nTo do this, we apply filter to detect any titles that starts with any character from A to Z. We don’t necessarily need to worry about case-sensitivity here since we are dealing with the first letter of the title which will always be capitalized already. Then I extract the first character from all the titles and further group by the characters to count them.\n\nN_firstword &lt;- USfilms |&gt;\nfilter(str_detect(title, \"^[A-Z]\")) |&gt; # Filter titles starting with uppercase letters\n  mutate(first_word = str_extract(title, \"^\\\\w\")) |&gt; # Extract the first word (not just the first letter)\n  group_by(first_word) |&gt; # Group by the first word\n  mutate(count = n()) # Add a count of occurrences within each group\n\nprint(N_firstword)\n\n# A tibble: 3,241 × 5\n# Groups:   first_word [26]\n   title                                   country        type  first_word count\n   &lt;chr&gt;                                   &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt;      &lt;int&gt;\n 1 A 3 Minute Hug                          Mexico, Unite… Movie A            223\n 2 A Babysitter's Guide to Monster Hunting United States  Movie A            223\n 3 A Bad Moms Christmas                    United States… Movie A            223\n 4 A Boy Called Po                         United States  Movie A            223\n 5 A Bridge Too Far                        United States… Movie A            223\n 6 A California Christmas                  United States  Movie A            223\n 7 A Champion Heart                        United States  Movie A            223\n 8 A Christmas Prince                      United States  Movie A            223\n 9 A Christmas Prince: The Royal Baby      United States  Movie A            223\n10 A Christmas Prince: The Royal Wedding   United States  Movie A            223\n# ℹ 3,231 more rows\n\n\nWith the information of each letter and the occurrences now we can visualize it by using a ggplot to create a bar chart!\n\nlibrary(ggplot2)\n\nggplot(N_firstword, aes(x= first_word, fill=type)) +\n   geom_bar() +\n  labs(title = \"Occurrences of different first letter in US Netflix Productions\",\n       x = \"First Letter of the title (A ~Z)\",\n       y = \"Number of Occurrences\") \n\n\n\n\n\n\n\n\nAccording to the graph, the most frequent first letter in the US Netflix production is “T” with a somewhat balanced distribution between movies and TV shows, the reason behind this is pretty easy to understand since most of the movie and TV shows may start with the word ‘The’."
  },
  {
    "objectID": "Text-Analysis.html#part-two-first-number-of-the-production-title",
    "href": "Text-Analysis.html#part-two-first-number-of-the-production-title",
    "title": "Project 2: Text Analysis",
    "section": "Part Two: First Number of the Production Title",
    "text": "Part Two: First Number of the Production Title\nIn addition to our part 1, now we are examining the different numbers as the first digit of the Netflix production title particularly the ones made in US. For this project, we can continuing using the information we obtained in the first part. However, for part two, we will use filter to detect titles that starts with a digit. Also, repeating a similar step of extracting the first digit and group by the numbers to better have a count of the occurrences.\n\nN_firstdigit &lt;- USfilms |&gt;\n  filter(str_detect(title, \"^\\\\d+\")) |&gt;\n  mutate(first_digit = str_extract(title, \"^\\\\d\")) |&gt;\n  group_by(first_digit) |&gt;\n  mutate(count = n())\n\nprint(N_firstdigit)\n\n# A tibble: 49 × 5\n# Groups:   first_digit [8]\n   title            country                        type    first_digit count\n   &lt;chr&gt;            &lt;chr&gt;                          &lt;chr&gt;   &lt;chr&gt;       &lt;int&gt;\n 1 9                United States                  Movie   9               2\n 2 21               United States                  Movie   2               8\n 3 187              United States                  Movie   1              21\n 4 1922             United States                  Movie   1              21\n 5 1983             Poland, United States          TV Show 1              21\n 6 3022             United States                  Movie   3               5\n 7 22-Jul           Norway, Iceland, United States Movie   2               8\n 8 1 Chance 2 Dance United States                  Movie   1              21\n 9 1 Mile to You    United States                  Movie   1              21\n10 10,000 B.C.      United States, South Africa    Movie   1              21\n# ℹ 39 more rows\n\n\nAnd now we visualize it!\n\n ggplot(N_firstdigit, aes(x= first_digit, fill=type)) +\n   geom_bar() +\n  labs(title = \"Occurrences of different first digit in US Netflix Productions\",\n       x = \"First Digit (0~9)\",\n       y = \"Number of Occurrences\") \n\n\n\n\n\n\n\n\nThe graph also displays a pretty interesting fact, which is that the digit “1” appear the most in both movies and TV shows in US Netflix production. I suspect that the reason may be because Many documentary titles or reality shows often include a numeric element, such as rankings or competitions, and those often start with number ‘1’.\nSome other interesting fact is that there is no TV shows title that starts with the digit ‘2’ or ‘4’ and there is no Movies title that starts with the digit ‘7’ in the US Netflix production.\n\nInsight\nThe analysis of first letters in US Netflix productions reveals some intriguing patterns:\n\nDominance of “T”: The letter “T” is the most common starting letter for titles. This is likely due to the prevalence of titles that begin with “The,” a common article in English.\nPrevalence of the Digit “1”: The digit “1” appears most frequently as the starting digit in both movies and TV shows.\nAbsence of Titles Starting with Certain Digits: There are no TV shows starting with the digit “2” or “4,” possibly indicating a lack of popular content or marketing focus. Similarly, no movies begin with “7,” which may reflect industry naming trends or a scarcity of suitable productions.\n\n\n\nReference\nThe data set Netflix_Titles comes from Kaggle w/ credit to Shivam Bansal, who is an experienced data science professional with a blend of full-stack engineering skills, pre-sales, and business skills. He is also a director for smaller scale video contents, to which inspired he to collect and update the data-sets for not just Netflix, but also many other video streaming platforms such as Amazon Prime , Disney+, and Hulu."
  },
  {
    "objectID": "Simulation.html",
    "href": "Simulation.html",
    "title": "Project 3: Simulation",
    "section": "",
    "text": "For this project, we aimed to construct a simulation of students doing course registration at the Claremont Colleges to obtain a quantitative information on the probability of getting into the class the student wanted.\nIn order to create this simulation, We first defined a function that simulate the registration action, which take the class size and the number of students that is planning to take the class. next we random shuffle students into a list that represent the order of course registration time. Last, we define the result for whether one particular student can get into the class such True: the student can get into the class, or False: the student would not get into the class.\n\nlibrary(purrr)\nsimulate_registration &lt;- function(class_size, num_students) {\n  random &lt;- sample(1:num_students)  # Randomly shuffle students\n  \n  registered_students &lt;- random[1:class_size]  # Select the first 'class_size' students\n  return(ifelse(1 %in% registered_students, TRUE, FALSE))  # if the student is registered\n}\n\nAfter we finish setting up and defining the function, now we run it with map to rerun and simulate the event. For our simulation, because of how small the class at the Claremont colleges normally are, let’s put 20 as the class_size for this imaginary class. For the students number, although the total students number may be high, however, we should only consider the number of students that may be interested into taking this imaginary class, thus let’s assume there are 50 students wanting to get into this class.\nFor number of simulations, I choose to run 1000 times because in probability simulations, running multiple trials reduces random variability and gives a more stable estimate of the true probability.\n\nclass_size &lt;- 20\nnum_students &lt;- 50\nnum_simulations &lt;- 1000\n\n# Run simulations\nresults &lt;- map_int(1:num_simulations, ~ simulate_registration(class_size = class_size, num_students = num_students))\n\n# Calculate the probability that student can gets a spot\nnum_true &lt;- sum(results == 1)\nprobability &lt;- num_true / num_simulations\n\n# Print the result\nprint(paste(\"Probability that student 1 gets a spot:\", probability))\n\n[1] \"Probability that student 1 gets a spot: 0.403\"\n\n\nAfter a few trials of 1000 times simulations, the general probability value we are getting are between 0.38 ~ 0.42, which basically concluded that for this course registration simulation with 50 students trying to get in a 20 spot class, the probability of getting in is around 0.4.\n\nlibrary(ggplot2)\n\n\nresults_df &lt;- data.frame(\n  Status = c(\"Not Registered\", \"Registered\"),\n  Proportion = c(1 - probability, probability)\n)\n\n\nggplot(results_df, aes(x= 1, y = Proportion, fill = Status)) +\n  geom_bar(stat = \"identity\") +\n  labs(title = \"Proportion of Student Getting a Spot in the Class\",\n       x = \"\",\n       y = \"Proportion\") +\n  theme_minimal()+\n  scale_fill_manual(values = c(\"Registered\" = \"lightgreen\", \"Not Registered\" = \"gray\"))\n\n\n\n\n\n\n\n\nThis plot display the results that we run, which is whether the student gets into the class. As the graph displays, the proportion of a student getting into the class is slight below 50% particularly around the 40% range. On the other hand, the proportion of student not getting into the class they want is around 60%.\n\nConclusion\nFor this project, we use R to simulate the course registration event here at 5C colleges, although the numbers we input are very much based on assumptions, we do successfully use R to simulate and get a sense of the probabilities of 1 student getting into the class that 50 students are interested in.\nSome possible limitation or improvement for future simulation:\n\nCould potentially take the concept of ‘majors’ into consideration as they tends to have a prioritizes when registering for their major classes.\nCould take into consideration of the registration time being weighted towards upperclassman\nIn the similar manner, we can also take into consideration of ‘perms’ since this is the way professor approve or disapprove students’ ability to register the class."
  },
  {
    "objectID": "SQL.html",
    "href": "SQL.html",
    "title": "Project 4: SQL",
    "section": "",
    "text": "library(dbplyr)\nlibrary(dplyr)\n\n\nlibrary(RMariaDB)\ncon_wai &lt;- dbConnect(\n  MariaDB(), host = \"scidb.smith.edu\",\n  user = \"waiuser\", password = \"smith_waiDB\", \n  dbname = \"wai\"\n)\nMeasurements &lt;- tbl(con_wai, \"Measurements\")\nPI_Info &lt;- tbl(con_wai, \"PI_Info\")\nSubjects &lt;- tbl(con_wai, \"Subjects\")\n\n\nSHOW TABLES;\n\n\n7 records\n\n\nTables_in_wai\n\n\n\n\nCodebook\n\n\nMeasurements\n\n\nMeasurements_pre2020\n\n\nPI_Info\n\n\nPI_Info_OLD\n\n\nSubjects\n\n\nSubjects_pre2020\n\n\n\n\n\n\nPart 1: Duplicating the graph\nFor this project, we are duplicate the Figure 1 from Voss (2020). We will query the WAI Database and build a data set in order to graph using ggplot.\nStep 1: Selecting the components that we need for the graph which includes identifier (only the studies that were shown in the original graph), instruments, frequency, absorbence and etc.\n\nSELECT \n    Identifier, Instrument, \n    COUNT(DISTINCT CONCAT(SubjectNumber, Ear)) AS Unique_Ears,\n    Frequency,\n    AVG(Absorbance) AS MeanAbsorbance\nFROM Measurements\nWHERE Identifier IN ('Abur_2014', 'Feeney_2017', 'Groon_2015', \n                     'Lewis_2015', 'Liu_2008', 'Rosowski_2012', \n                     'Shahnaz_2006', 'Shaver_2013', 'Sun_2016', \n                     'Voss_1994', 'Voss_2010', 'Werner_2010')\nGROUP BY Identifier, Instrument, Frequency\nORDER BY Frequency;\n\n\nDisplaying records 1 - 10\n\n\nIdentifier\nInstrument\nUnique_Ears\nFrequency\nMeanAbsorbance\n\n\n\n\nLewis_2015\nOther\n14\n0.00000\n0.9999481\n\n\nLewis_2015\nOther\n14\n5.85938\n0.9999481\n\n\nLewis_2015\nOther\n14\n11.71880\n0.9999481\n\n\nLewis_2015\nOther\n14\n17.57810\n0.0942423\n\n\nLewis_2015\nOther\n14\n23.43750\n0.0955518\n\n\nLewis_2015\nOther\n14\n29.29690\n0.0972262\n\n\nLewis_2015\nOther\n14\n35.15620\n0.0992588\n\n\nVoss_1994\npreHearID\n10\n39.06250\n-0.0280960\n\n\nLewis_2015\nOther\n14\n41.01560\n0.1016413\n\n\nLewis_2015\nOther\n14\n46.87500\n0.1043644\n\n\n\n\n\n\ngraph_data &lt;- \"\nSELECT \n    m.Identifier,\n    m.Instrument,\n    COUNT(DISTINCT CONCAT(m.SubjectNumber, m.Ear)) AS Unique_Ears, -- Count unique ears\n    m.Frequency,\n    AVG(m.Absorbance) AS MeanAbsorbance\nFROM Measurements m\nWHERE m.Identifier IN ('Abur_2014', 'Feeney_2017', 'Groon_2015', \n                        'Lewis_2015', 'Liu_2008', 'Rosowski_2012', \n                        'Shahnaz_2006', 'Shaver_2013', 'Sun_2016', \n                        'Voss_1994', 'Voss_2010', 'Werner_2010')\n  AND m.Frequency &gt; 200 -- Filter relevant frequencies\n  AND m.Frequency &lt; 8000 -- Align with the x-axis scale\nGROUP BY m.Identifier, m.Instrument, m.Frequency\nORDER BY m.Identifier, m.Frequency;\n\"\n\nStep 2: using ggplot to graph, setting frequency as x-axis; Mean absorbance as y-axis; and identifier as the color to distinct between studies.\n\ngraph_plot &lt;- dbGetQuery(con_wai, graph_data)\n\nlibrary(ggplot2)\n\nggplot(graph_plot, aes(x = Frequency, y = MeanAbsorbance, color = Identifier)) +\n  geom_line() +\n  scale_x_log10() + \n  labs(\n    title = \"Mean Absorbance from Each Publication in WAI Database\",\n    x = \"Frequency (Hz)\",\n    y = \"Mean Absorbance\") +\n    theme_minimal() \n\n\n\n\n\n\n\n\nThe graph displays the mean absorbance on y-axis across different frequencies (Hz) on x-axis for multiple studies, each represented by a distinct colored line. The graph compares how absorbance patterns vary by frequency among studies using different systems.\n\n\nPart 2 - Specific Group of interest\nFor part 2, we are examining subjects with different race, especially Black and Caucasian.\nSimilar to the first part, we start by selecting the components we need and here I was hoping to identity the studies with more than one distinct race and also to have at least one subject with a known race within these studies.\n\nSELECT \n    Identifier,\n    COUNT(*) AS Total_Subjects,\n    COUNT(DISTINCT Race) AS Race_Groups,\n    SUM(CASE WHEN Race = 'Unknown' THEN 1 ELSE 0 END) AS Unknown\nFROM Subjects\nGROUP BY Identifier\nHAVING Race_Groups &gt; 1 AND (Total_Subjects - Unknown) &gt; 0; \n\n\nDisplaying records 1 - 10\n\n\nIdentifier\nTotal_Subjects\nRace_Groups\nUnknown\n\n\n\n\nAithal_2014b\n184\n2\n0\n\n\nAithal_2015\n141\n4\n0\n\n\nDowning_2022\n924\n7\n108\n\n\nEllison_2012\n88\n5\n4\n\n\nHunter_2016\n182\n3\n0\n\n\nKeefe_2012\n55\n5\n10\n\n\nLewis_2015\n14\n4\n0\n\n\nMerchant_2015\n32\n3\n4\n\n\nMerchant_2020\n29\n2\n0\n\n\nMerchant_2021\n35\n4\n1\n\n\n\n\n\n\nquery_race &lt;- \"\nSELECT \n    Identifier,\n    COUNT(*) AS Total_Subjects,\n    COUNT(DISTINCT Race) AS Race_Groups,\n    SUM(CASE WHEN Race = 'Unknown' THEN 1 ELSE 0 END) AS Unknown\nFROM Subjects\nGROUP BY Identifier\nHAVING Race_Groups &gt; 1 AND (Total_Subjects - Unknown) &gt; 0;\"\n\ndiverse_studies &lt;- dbGetQuery(con_wai, query_race)\n\nprint(diverse_studies)\n\n      Identifier Total_Subjects Race_Groups Unknown\n1   Aithal_2014b            184           2       0\n2    Aithal_2015            141           4       0\n3   Downing_2022            924           7     108\n4   Ellison_2012             88           5       4\n5    Hunter_2016            182           3       0\n6     Keefe_2012             55           5      10\n7     Lewis_2015             14           4       0\n8  Merchant_2015             32           3       4\n9  Merchant_2020             29           2       0\n10 Merchant_2021             35           4       1\n11    Myers_2018            543           7     151\n12 Nakajima_2012             30           3      17\n13 Rosowski_2012             29           4       0\n14  Shahnaz_2006            126           2       0\n15   Shaver_2013             48           4       1\n16      Sun_2016             84           5       2\n17      Sun_2023           3582           4       0\n\n\nThen, using the information we retrieved, calculate and summarize mean absorbance values for specific studies across different frequencies for two racial groups, in this case is “Black” and “Caucasian”.\n\n\nSELECT \n    m.Identifier,       \n    s.Race AS GroupName,  \n    m.Frequency,         \n    AVG(m.Absorbance) AS MeanAbsorbance \nFROM Measurements m\nJOIN Subjects s \n    ON m.SubjectNumber = s.SubjectNumber\n    AND m.Identifier = s.Identifier\nWHERE m.Identifier IN ('Abur_2014', 'Feeney_2017', 'Groon_2015', \n                        'Lewis_2015', 'Liu_2008', 'Rosowski_2012', \n                        'Shahnaz_2006', 'Shaver_2013', 'Sun_2016', \n                        'Voss_1994', 'Voss_2010', 'Werner_2010') \n  AND m.Frequency &gt; 200            \n  AND m.Frequency &lt; 8000\n  AND m.Absorbance &gt;= 0            \n  AND s.Race IN ( 'Black', 'Caucasian')   \nGROUP BY m.Identifier, s.Race, m.Frequency \nORDER BY m.Identifier, s.Race, m.Frequency;\n\n\nDisplaying records 1 - 10\n\n\nIdentifier\nGroupName\nFrequency\nMeanAbsorbance\n\n\n\n\nLewis_2015\nBlack\n205.078\n0.2449420\n\n\nLewis_2015\nBlack\n210.938\n0.2506140\n\n\nLewis_2015\nBlack\n216.797\n0.2561765\n\n\nLewis_2015\nBlack\n222.656\n0.2616243\n\n\nLewis_2015\nBlack\n228.516\n0.2669527\n\n\nLewis_2015\nBlack\n234.375\n0.2721585\n\n\nLewis_2015\nBlack\n240.234\n0.2772395\n\n\nLewis_2015\nBlack\n246.094\n0.2821955\n\n\nLewis_2015\nBlack\n251.953\n0.2870257\n\n\nLewis_2015\nBlack\n257.812\n0.2917315\n\n\n\n\n\n\nquery_race &lt;- \"\n\nSELECT \n    m.Identifier,       \n    s.Race AS GroupName,  \n    m.Frequency,         \n    AVG(m.Absorbance) AS MeanAbsorbance \nFROM Measurements m\nJOIN Subjects s \n    ON m.SubjectNumber = s.SubjectNumber\n    AND m.Identifier = s.Identifier\nWHERE m.Identifier IN ('Abur_2014', 'Feeney_2017', 'Groon_2015', \n                        'Lewis_2015', 'Liu_2008', 'Rosowski_2012', \n                        'Shahnaz_2006', 'Shaver_2013', 'Sun_2016', \n                        'Voss_1994', 'Voss_2010', 'Werner_2010') \n  AND m.Frequency &gt; 200            \n  AND m.Frequency &lt; 8000\n  AND m.Absorbance &gt;= 0            \n  AND s.Race IN ( 'Black', 'Caucasian')  \nGROUP BY m.Identifier, s.Race, m.Frequency \nORDER BY m.Identifier, s.Race, m.Frequency;\"\n\n\ndata_absorption &lt;- dbGetQuery(con_wai, query_race)\n\n\nhead(data_absorption)\n\n  Identifier GroupName Frequency MeanAbsorbance\n1 Lewis_2015 Black       205.078      0.2449420\n2 Lewis_2015 Black       210.938      0.2506140\n3 Lewis_2015 Black       216.797      0.2561765\n4 Lewis_2015 Black       222.656      0.2616243\n5 Lewis_2015 Black       228.516      0.2669527\n6 Lewis_2015 Black       234.375      0.2721585\n\n\nNext, we use ggplot to plot the graph, same as part 1, Frequency as x-axis; MeanAbsorbance as y-axis; however, here the color will be GroupName which will be different group of subject, indicating different races.\n\nggplot(data_absorption, aes(x = Frequency, y = MeanAbsorbance, color = GroupName)) +\n  geom_line() +\n  facet_wrap(~ Identifier) +  \n  scale_x_log10() +          \n  labs(\n    title = \"Mean Absorbance by Ethnicity Across Multiple Studies\",\n    x = \"Frequency (Hz)\",\n    y = \"Mean Absorbance\",\n    color = \"Race\"\n  ) +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThis graph presents the mean absorbance on the y-axis across frequencies (Hz) on the x-axis for Black and Caucasian subjects, with separate panels representing data from different studies. It highlights variations in absorbance patterns by race within each study, showing both similarities and potential differences in the trends across frequencies.\nFor the Lewis_2015 study and Rosowski_2012 study, both display minimal or no differences in absorbance between Black and Caucasian subjects, however, for the Shaver_2013 and Sun_2016 studies, both indicate significant racial differences, with Black subjects generally exhibiting higher absorbance, especially at lower and mid-frequencies. While Shahnaz_2006 lacks data for Black subjects, therefore there is only one line. Overall, racial differences in absorbance trends appear study-specific, with some studies showing marked variation and others showing uniformity."
  },
  {
    "objectID": "Presentation.html#project-text-analysis",
    "href": "Presentation.html#project-text-analysis",
    "title": "Presentation",
    "section": "Project: Text Analysis",
    "text": "Project: Text Analysis\n\nstr_*() functions and regular expressions\nNetflix Movies and TV Shows Data set\nThe data set comes from Kaggle w/ credit to Shivam Bansal\n\n\nlibrary(\"tidytuesdayR\")\nlibrary(\"tidyverse\")\n\nnetflix_titles &lt;- readr::read_csv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2021/2021-04-20/netflix_titles.csv')\n\nshow_col_types = FALSE"
  },
  {
    "objectID": "Presentation.html#shivam-bansal",
    "href": "Presentation.html#shivam-bansal",
    "title": "Presentation",
    "section": "Shivam Bansal",
    "text": "Shivam Bansal\n\nAn experienced data science professional with a blend of full-stack engineering skills, pre-sales, and business skills\nA director for smaller scale video contents\nData-sets for not just Netflix, but also many other video streaming platforms such as Amazon Prime, Disney+, and Hulu."
  },
  {
    "objectID": "Presentation.html#focus-on-us-based-productions",
    "href": "Presentation.html#focus-on-us-based-productions",
    "title": "Presentation",
    "section": "Focus on US based productions",
    "text": "Focus on US based productions\n\nlibrary(dplyr)\nlibrary(stringr)\n\nUSfilms &lt;- netflix_titles |&gt; \n    filter(str_detect(country, \"United States\")) |&gt; # Filter for US-based titles\n  select(title, country, type) |&gt; # Select only the relevant columns\n  filter(!is.na(everything)) # Remove rows with NA values in any of the selected columns"
  },
  {
    "objectID": "Presentation.html#organize-the-data-to-find-first-character",
    "href": "Presentation.html#organize-the-data-to-find-first-character",
    "title": "Presentation",
    "section": "Organize the data to find first character",
    "text": "Organize the data to find first character\n\nN_firstword &lt;- USfilms |&gt;\nfilter(str_detect(title, \"^[A-Z]\")) |&gt; # Filter titles starting with uppercase letters\n  mutate(first_word = str_extract(title, \"^\\\\w\")) |&gt; # Extract the first word (not just the first letter)\n  group_by(first_word) |&gt; # Group by the first word\n  mutate(count = n()) # Add a count of occurrences within each group\n\nprint(N_firstword)\n\n# A tibble: 3,241 × 5\n# Groups:   first_word [26]\n   title                                   country        type  first_word count\n   &lt;chr&gt;                                   &lt;chr&gt;          &lt;chr&gt; &lt;chr&gt;      &lt;int&gt;\n 1 A 3 Minute Hug                          Mexico, Unite… Movie A            223\n 2 A Babysitter's Guide to Monster Hunting United States  Movie A            223\n 3 A Bad Moms Christmas                    United States… Movie A            223\n 4 A Boy Called Po                         United States  Movie A            223\n 5 A Bridge Too Far                        United States… Movie A            223\n 6 A California Christmas                  United States  Movie A            223\n 7 A Champion Heart                        United States  Movie A            223\n 8 A Christmas Prince                      United States  Movie A            223\n 9 A Christmas Prince: The Royal Baby      United States  Movie A            223\n10 A Christmas Prince: The Royal Wedding   United States  Movie A            223\n# ℹ 3,231 more rows"
  },
  {
    "objectID": "Presentation.html#ggplot",
    "href": "Presentation.html#ggplot",
    "title": "Presentation",
    "section": "ggplot",
    "text": "ggplot\n\nlibrary(ggplot2)\n\nggplot(N_firstword, aes(x= first_word, fill=type)) +\n   geom_bar() +\n  labs(title = \"Occurrences of different first letter in US Netflix Productions\",\n       x = \"First Letter of the title (A ~Z)\",\n       y = \"Number of Occurrences\")"
  },
  {
    "objectID": "Presentation.html#organize-the-data-to-find-first-digit",
    "href": "Presentation.html#organize-the-data-to-find-first-digit",
    "title": "Presentation",
    "section": "Organize the data to find first digit",
    "text": "Organize the data to find first digit\n\nN_firstdigit &lt;- USfilms |&gt;\n  filter(str_detect(title, \"^\\\\d+\")) |&gt;\n  mutate(first_digit = str_extract(title, \"^\\\\d\")) |&gt;\n  group_by(first_digit) |&gt;\n  mutate(count = n())\n\nprint(N_firstdigit)\n\n# A tibble: 49 × 5\n# Groups:   first_digit [8]\n   title            country                        type    first_digit count\n   &lt;chr&gt;            &lt;chr&gt;                          &lt;chr&gt;   &lt;chr&gt;       &lt;int&gt;\n 1 9                United States                  Movie   9               2\n 2 21               United States                  Movie   2               8\n 3 187              United States                  Movie   1              21\n 4 1922             United States                  Movie   1              21\n 5 1983             Poland, United States          TV Show 1              21\n 6 3022             United States                  Movie   3               5\n 7 22-Jul           Norway, Iceland, United States Movie   2               8\n 8 1 Chance 2 Dance United States                  Movie   1              21\n 9 1 Mile to You    United States                  Movie   1              21\n10 10,000 B.C.      United States, South Africa    Movie   1              21\n# ℹ 39 more rows"
  },
  {
    "objectID": "Presentation.html#ggplot-1",
    "href": "Presentation.html#ggplot-1",
    "title": "Presentation",
    "section": "ggplot",
    "text": "ggplot\n\n ggplot(N_firstdigit, aes(x= first_digit, fill=type)) +\n   geom_bar() +\n  labs(title = \"Occurrences of different first digit in US Netflix Productions\",\n       x = \"First Digit (0~9)\",\n       y = \"Number of Occurrences\")"
  },
  {
    "objectID": "Presentation.html#insight",
    "href": "Presentation.html#insight",
    "title": "Presentation",
    "section": "insight",
    "text": "insight\nThe analysis of first letters in US Netflix productions reveals some intriguing patterns:\n\nDominance of “T”: The letter “T” is the most common starting letter for titles. This is likely due to the prevalence of titles that begin with “The,” a common article in English.\nPrevalence of the Digit “1”: The digit “1” appears most frequently as the starting digit in both movies and TV shows.\nAbsence of Titles Starting with Certain Digits: There are no TV shows starting with the digit “2” or “4,” possibly indicating a lack of popular content or marketing focus. Similarly, no movies begin with “7,” which may reflect industry naming trends or a scarcity of suitable productions."
  },
  {
    "objectID": "shinyapp.html",
    "href": "shinyapp.html",
    "title": "Shiny App - ExtraCredit",
    "section": "",
    "text": "Shiny App - ExtraCredit\nThis is a Rock Paper Scissor Game for my Extra Credit Shiny project\nlibrary(shiny)\n\n\nDefine your UI\nui &lt;- fluidPage( titlePanel(“Rock-Paper-Scissors Game”), sidebarLayout( sidebarPanel( h3(“Choose your move:”), radioButtons(“user_choice”, “Your choice:”, choices = list(“Rock”, “Paper”, “Scissors”), selected = “Rock”), actionButton(“play”, “Play Game”) ), mainPanel( h4(“Game Result:”), textOutput(“result”), br(), textOutput(“computer_choice”), br(), textOutput(“score”) ) ) )\n\n\nDefine your server logic\nserver &lt;- function(input, output, session) { score &lt;- reactiveVal(list(user = 0, computer = 0)) computer_choice &lt;- function() { sample(c(“Rock”, “Paper”, “Scissors”), 1) }\ndetermine_winner &lt;- function(user, computer) { if (user == computer) { return(“It’s a tie!”) } if ((user == “Rock” && computer == “Scissors”) || (user == “Paper” && computer == “Rock”) || (user == “Scissors” && computer == “Paper”)) { return(“You win!”) } else { return(“Computer wins!”) } }\nupdate_score &lt;- function(winner) { current_score &lt;- score() if (winner == “You win!”) { current_score\\(user &lt;- current_score\\)user + 1 } else if (winner == “Computer wins!”) { current_score\\(computer &lt;- current_score\\)computer + 1 } score(current_score) }\nobserveEvent(input\\(play, {\n    user_move &lt;- input\\)user_choice comp_move &lt;- computer_choice() game_result &lt;- determine_winner(user_move, comp_move) update_score(game_result)\noutput$result &lt;- renderText({ game_result })\noutput$computer_choice &lt;- renderText({ paste(\"Computer chose:\", comp_move) })\noutput$score &lt;- renderText({\n  paste(\"Score - You: \", score()$user, \" Computer: \", score()$computer)\n})\n}) }\nshinyApp(ui = ui, server = server)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Welcome! This is Jessica’s website",
    "section": "",
    "text": "Hello! Nice to meet you!\nMy name is Jessica, I am a international student from Taiwan, and currently a junior at Pitzer College, pursuing a combined major in Organizational Studies and Psychology with a minor in Data Science. My academic journey has equipped me with a strong understanding of human behavior and organizational dynamics, allowing me to explore the intersection of psychology and effective management practices along with my data analysis skills.\n\n\nLet’s stay connected!\nLinkedIn\nGitHub\nEmail:jeslin@students.pitzer.edu"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Me",
    "section": "",
    "text": "Kaohsiung American School: High School diploma\nPitzer College: Bachelor of Arts (B.A.) in Organizational Studies and Psychology; Minor in Data Science."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Me",
    "section": "",
    "text": "Kaohsiung American School: High School diploma\nPitzer College: Bachelor of Arts (B.A.) in Organizational Studies and Psychology; Minor in Data Science."
  },
  {
    "objectID": "about.html#professional-experience",
    "href": "about.html#professional-experience",
    "title": "About Me",
    "section": "Professional Experience",
    "text": "Professional Experience\nAdmission operation Assistant\nInternational Students Orientation Assistant\nStudent Success Assistant\nAcademic Guide"
  },
  {
    "objectID": "about.html#leaderships",
    "href": "about.html#leaderships",
    "title": "About Me",
    "section": "Leaderships",
    "text": "Leaderships\nPitzer International Students Association (PISA)\nThe Pasifika Asian Student Union (PASU)"
  }
]